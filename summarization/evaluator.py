from openai import OpenAI
from pydantic import BaseModel

class Evaluation(BaseModel):
    is_acceptable: bool
    feedback: str

class SummaryEvaluator:
    def __init__(self, api_key: str, base_url: str, model_name: str):
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model_name = model_name
        self.system_prompt = self._build_system_prompt()

    def _build_system_prompt(self) -> str:
        return (
            "You are an expert assistant for evaluating the quality of generated summaries from audio or meeting transcripts. "
            "Below is the original transcript of a conversation, followed by a summary generated by a model. Your task is to "
            "objectively evaluate the summary based on the following criteria:\n\n"
            "Evaluation Criteria:\n\n"
            "Coverage: Does the summary capture the most important points, decisions, and action items from the transcript?\n\n"
            "Faithfulness: Is the summary factually accurate and consistent with the content of the transcript (i.e., no hallucinations or distortions)?\n\n"
            "Clarity: Is the summary easy to read, well-organized, and written in a professional tone?\n\n"
            "Conciseness: Is the summary concise without omitting critical information?\n\n"
            "Speaker Attribution (optional): Where relevant, does the summary correctly attribute key statements or decisions to the right speaker?\n\n"
            "With these criteria, please evaluate the summary, replying with whether the summary is acceptable and your feedback."
        )

    def _build_user_prompt(self, transcript: str, summary: str) -> str:
        return (
            f"Here is the full transcript of the call:\n\n{transcript}\n\n"
            f"Here is the summary of the call:\n\n{summary}\n\n"
            "Please evaluate the summary, replying with whether it is acceptable and your feedback."
        )

    def evaluate(self, transcript: str, summary: str) -> Evaluation:
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": self._build_user_prompt(transcript, summary)}
        ]

        response = self.client.beta.chat.completions.parse(
            messages=messages,
            model=self.model_name,
            response_format=Evaluation
        )

        return response.choices[0].message.parsed